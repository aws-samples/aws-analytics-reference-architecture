apiVersion: karpenter.sh/v1alpha5
kind: Provisioner
metadata:
  name: sparkcapacity
spec:
  # References cloud provider-specific custom resource, see your cloud provider specific documentation
  providerRef:
    name: sparkinstance

  # Labels are arbitrary key-values that are applied to all nodes
  labels:
    app: spark

  # Requirements that constrain the parameters of provisioned nodes.
  # These requirements are combined with pod.spec.affinity.nodeAffinity rules.
  # Operators { In, NotIn } are supported to enable including or excluding values
  requirements:
    # Include general purpose instance families
    - key: karpenter.k8s.aws/instance-family
      operator: In
      values: [c5, m5, r5]
    # Exclude smaller instance sizes
    - key: karpenter.k8s.aws/instance-size
      operator: NotIn
      values: [nano, micro, small]
    # Exclude a specific instance type
    - key: node.kubernetes.io/instance-type
      operator: NotIn
      values: [m5.24xlarge]
    - key: "karpenter.sh/capacity-type" # If not included, the webhook for the AWS cloud provider will default to on-demand
      operator: In
      values: ["spot", "on-demand"]

  # Resource limits constrain the total size of the cluster.
  # Limits prevent Karpenter from creating new instances once the limit is exceeded.
  limits:
    resources:
      cpu: "100"
      memory: 100Gi

  # Priority given to the provisioner when the scheduler considers which provisioner
  # to select. Higher weights indicate higher priority when comparing provisioners.
  # Specifying no weight is equivalent to specifying a weight of 0.
  weight: 10
  
---
apiVersion: karpenter.k8s.aws/v1alpha1
kind: AWSNodeTemplate
metadata:
  name: sparkinstance
spec:
  subnetSelector:
    karpenter.sh/discovery: "araKarpenterClusterRef"
  securityGroupSelector:
    karpenter.sh/discovery: "araKarpenterClusterRef"
  tags:
    KarpenerProvisionerName: "sparkcapacity"
    IntentLabel: "spark"